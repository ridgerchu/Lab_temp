Not using distributed mode
Namespace(T=4, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_url='env://', distributed=False, epochs=90, interpolation='bilinear', label_smoothing=0.1, local_rank=None, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=16, world_size=1)
Loading data
Loading training data
Took 0.48298120498657227
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (2): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (6): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (10): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (20): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (24): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (27): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)
| distributed init (rank 0): env://
| distributed init (rank 1): env://
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_backend='nccl', dist_url='env://', distributed=True, epochs=90, gpu=0, interpolation='bilinear', label_smoothing=0.1, local_rank=0, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, rank=0, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=16, world_size=2)
Loading data
Loading training data
Took 0.7546541690826416
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (2): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (6): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (10): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (20): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (24): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (27): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)
| distributed init (rank 1): env://
| distributed init (rank 0): env://
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_backend='nccl', dist_url='env://', distributed=True, epochs=90, gpu=0, interpolation='bilinear', label_smoothing=0.1, local_rank=0, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, rank=0, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=16, world_size=2)
Loading data
Loading training data
Took 0.747814416885376
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (2): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (6): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (10): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (20): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (24): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (27): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=200, bias=True)
  )
)
| distributed init (rank 0): env://
| distributed init (rank 1): env://
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_backend='nccl', dist_url='env://', distributed=True, epochs=90, gpu=0, interpolation='bilinear', label_smoothing=0.1, local_rank=0, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, rank=0, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=16, world_size=2)
Loading data
Loading training data
Took 0.7262935638427734
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (2): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (6): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (10): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (20): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (24): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (27): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=200, bias=True)
  )
)
| distributed init (rank 0): env://
| distributed init (rank 1): env://
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_backend='nccl', dist_url='env://', distributed=True, epochs=90, gpu=0, interpolation='bilinear', label_smoothing=0.1, local_rank=0, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, rank=0, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=16, world_size=2)
Loading data
Loading training data
Took 0.7351021766662598
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (2): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (6): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (10): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (20): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (24): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (27): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=200, bias=True)
  )
)
| distributed init (rank 0): env://
| distributed init (rank 1): env://
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_backend='nccl', dist_url='env://', distributed=True, epochs=90, gpu=0, interpolation='bilinear', label_smoothing=0.1, local_rank=0, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, rank=0, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=16, world_size=2)
Loading data
Loading training data
Took 0.7510473728179932
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (2): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (6): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (10): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (20): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (24): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (27): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=200, bias=True)
  )
)
| distributed init (rank 0): env://
| distributed init (rank 1): env://
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_backend='nccl', dist_url='env://', distributed=True, epochs=90, gpu=0, interpolation='bilinear', label_smoothing=0.1, local_rank=0, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, rank=0, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=16, world_size=2)
Loading data
Loading training data
Took 0.7301974296569824
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (2): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (6): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (10): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (20): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (24): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (27): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=200, bias=True)
  )
)
Not using distributed mode
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_url='env://', distributed=False, epochs=90, interpolation='bilinear', label_smoothing=0.1, local_rank=None, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=16, world_size=1)
Loading data
Loading training data
Took 2.905100107192993
Loading validation data
Creating data loaders
Creating model
Not using distributed mode
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_url='env://', distributed=False, epochs=90, interpolation='bilinear', label_smoothing=0.1, local_rank=None, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=16, world_size=1)
Loading data
Loading training data
Took 2.3658769130706787
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(64, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(4, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (3): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (5): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(8, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (8): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (10): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (19): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (20): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (21): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (22): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (23): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (26): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (28): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (29): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (31): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (32): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (35): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=200, bias=True)
  )
)
Not using distributed mode
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_url='env://', distributed=False, epochs=90, interpolation='bilinear', label_smoothing=0.1, local_rank=None, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=0, world_size=1)
Loading data
Loading training data
Took 1.8917210102081299
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(64, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(4, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (3): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (5): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(8, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (8): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (10): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (19): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (20): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (21): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (22): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (23): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (26): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (28): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (29): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (31): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (32): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (35): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=200, bias=True)
  )
)
Not using distributed mode
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_url='env://', distributed=False, epochs=90, interpolation='bilinear', label_smoothing=0.1, local_rank=None, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=0, world_size=1)
Loading data
Loading training data
Took 2.117323398590088
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(64, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(4, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (3): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (5): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(8, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (8): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (10): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (19): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (20): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (21): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (22): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (23): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (26): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (28): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (29): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (31): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (32): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (35): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=200, bias=True)
  )
)
Not using distributed mode
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_url='env://', distributed=False, epochs=90, interpolation='bilinear', label_smoothing=0.1, local_rank=None, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=0, world_size=1)
Loading data
Loading training data
Took 1.7540886402130127
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(64, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(4, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (3): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (5): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(8, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (8): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (10): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (19): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (20): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (21): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (22): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (23): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (26): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (28): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (29): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (31): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (32): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (35): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=200, bias=True)
  )
)
Not using distributed mode
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_url='env://', distributed=False, epochs=90, interpolation='bilinear', label_smoothing=0.1, local_rank=None, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=0, world_size=1)
Loading data
Loading training data
Took 1.8094611167907715
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(64, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(4, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (3): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (5): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(8, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (8): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (10): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (19): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (20): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (21): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (22): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (23): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (26): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (28): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (29): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (31): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (32): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (35): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=200, bias=True)
  )
)
Not using distributed mode
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_url='env://', distributed=False, epochs=90, interpolation='bilinear', label_smoothing=0.1, local_rank=None, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=0, world_size=1)
Loading data
Loading training data
Took 2.5045971870422363
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(64, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(4, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (3): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (5): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(8, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (8): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (10): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (19): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (20): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (21): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (22): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (23): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (26): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (28): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (29): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (31): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (32): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (35): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=200, bias=True)
  )
)
Not using distributed mode
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_url='env://', distributed=False, epochs=90, interpolation='bilinear', label_smoothing=0.1, local_rank=None, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=0, world_size=1)
Loading data
Loading training data
Took 2.470684766769409
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(64, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(4, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (3): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (5): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(8, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (8): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (10): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (19): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (20): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (21): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (22): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (23): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (26): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (28): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (29): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (31): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (32): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (35): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=200, bias=True)
  )
)
Not using distributed mode
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_url='env://', distributed=False, epochs=90, interpolation='bilinear', label_smoothing=0.1, local_rank=None, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=0, world_size=1)
Loading data
Loading training data
Took 1.9577171802520752
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(64, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(4, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (3): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (5): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(8, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (8): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (10): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (19): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (20): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (21): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (22): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (23): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (26): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (28): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (29): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (31): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (32): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (35): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=200, bias=True)
  )
)
Not using distributed mode
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_url='env://', distributed=False, epochs=90, interpolation='bilinear', label_smoothing=0.1, local_rank=None, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=0, world_size=1)
Loading data
Loading training data
Took 2.1095619201660156
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(64, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(4, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (3): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (5): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(8, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (8): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (10): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (19): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (20): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (21): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (22): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (23): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (26): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (28): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (29): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (31): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (32): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (35): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=200, bias=True)
  )
)
Not using distributed mode
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_url='env://', distributed=False, epochs=90, interpolation='bilinear', label_smoothing=0.1, local_rank=None, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=0, world_size=1)
Loading data
Loading training data
Took 2.2114343643188477
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(64, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(4, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (3): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (5): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(8, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (8): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (10): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (19): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (20): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (21): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (22): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (23): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (26): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (28): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (29): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (31): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (32): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (35): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=200, bias=True)
  )
)
Not using distributed mode
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_url='env://', distributed=False, epochs=90, interpolation='bilinear', label_smoothing=0.1, local_rank=None, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=0, world_size=1)
Loading data
Loading training data
Took 1.837090015411377
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(64, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(4, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (3): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (5): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(8, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (8): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (10): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (19): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (20): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (21): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (22): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (23): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (26): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (28): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (29): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (31): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (32): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (35): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=200, bias=True)
  )
)
Not using distributed mode
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_url='env://', distributed=False, epochs=90, interpolation='bilinear', label_smoothing=0.1, local_rank=None, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=0, world_size=1)
Loading data
Loading training data
Took 2.628122329711914
Loading validation data
Creating data loaders
Creating model
Not using distributed mode
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_url='env://', distributed=False, epochs=90, interpolation='bilinear', label_smoothing=0.1, local_rank=None, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=0, world_size=1)
Loading data
Loading training data
Took 2.175746440887451
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(3, 0, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(0, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (3): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (5): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(64, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(4, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (8): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (10): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(8, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (19): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (20): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (21): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (22): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (23): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (26): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (28): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (29): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (31): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (32): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (35): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=200, bias=True)
  )
)
Not using distributed mode
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_url='env://', distributed=False, epochs=90, interpolation='bilinear', label_smoothing=0.1, local_rank=None, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=0, world_size=1)
Loading data
Loading training data
Took 2.0981500148773193
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(3, 0, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(0, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (3): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (5): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(64, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(4, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (8): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (10): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(8, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (19): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (20): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (21): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (22): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (23): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (26): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (28): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (29): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (31): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (32): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (35): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=200, bias=True)
  )
)
Not using distributed mode
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_url='env://', distributed=False, epochs=90, interpolation='bilinear', label_smoothing=0.1, local_rank=None, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=0, world_size=1)
Loading data
Loading training data
Took 2.170628547668457
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(3, 0, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(0, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (3): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (5): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(64, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(4, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (8): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (10): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(8, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (19): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (20): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (21): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (22): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (23): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (26): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (28): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (29): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (31): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (32): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (35): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=200, bias=True)
  )
)
Not using distributed mode
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_url='env://', distributed=False, epochs=90, interpolation='bilinear', label_smoothing=0.1, local_rank=None, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=0, world_size=1)
Loading data
Loading training data
Took 2.2596402168273926
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (1): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(64, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(4, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (3): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (6): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(8, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (8): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (11): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (15): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (20): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (21): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (22): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (24): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (26): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (29): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (31): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (33): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (35): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=200, bias=True)
  )
)
Not using distributed mode
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_url='env://', distributed=False, epochs=90, interpolation='bilinear', label_smoothing=0.1, local_rank=None, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=0, world_size=1)
Loading data
Loading training data
Took 1.7737915515899658
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (1): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(64, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(4, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (3): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (6): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(8, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (8): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (11): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (15): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (20): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (21): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (22): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (24): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (26): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (29): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (31): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (33): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (35): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=200, bias=True)
  )
)
Not using distributed mode
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_url='env://', distributed=False, epochs=90, interpolation='bilinear', label_smoothing=0.1, local_rank=None, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=0, world_size=1)
Loading data
Loading training data
Took 0.5457882881164551
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (1): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(64, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(4, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (3): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (6): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(8, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (8): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (11): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (15): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (20): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (21): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (22): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (24): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (26): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (29): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (31): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (33): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (35): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=200, bias=True)
  )
)
Not using distributed mode
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_url='env://', distributed=False, epochs=90, interpolation='bilinear', label_smoothing=0.1, local_rank=None, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=0, world_size=1)
Loading data
Loading training data
Took 0.75537109375
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (1): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(64, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(4, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (3): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (6): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(8, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (8): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (11): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (15): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (20): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (21): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (22): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (24): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (26): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (29): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (31): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (33): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (35): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=200, bias=True)
  )
)
Not using distributed mode
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_url='env://', distributed=False, epochs=90, interpolation='bilinear', label_smoothing=0.1, local_rank=None, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=0, world_size=1)
Loading data
Loading training data
Took 1.7991745471954346
Loading validation data
Creating data loaders
Creating model
Not using distributed mode
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_url='env://', distributed=False, epochs=90, interpolation='bilinear', label_smoothing=0.1, local_rank=None, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=0, world_size=1)
Loading data
Loading training data
Took 2.1159610748291016
Loading validation data
Creating data loaders
Not using distributed mode
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_url='env://', distributed=False, epochs=90, interpolation='bilinear', label_smoothing=0.1, local_rank=None, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=0, world_size=1)
Loading data
Loading training data
Took 1.8907432556152344
Loading validation data
Creating data loaders
Creating model
Not using distributed mode
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_url='env://', distributed=False, epochs=90, interpolation='bilinear', label_smoothing=0.1, local_rank=None, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=0, world_size=1)
Loading data
Loading training data
Took 1.9164857864379883
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (1): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(64, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(4, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (3): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (6): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(8, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (8): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (11): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (15): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (20): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (21): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (22): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (24): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (26): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (29): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (31): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (33): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (35): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=200, bias=True)
  )
)
Not using distributed mode
Namespace(T=1, auto_augment='ta_wide', batch_size=16, cache_dataset=False, clean=False, clip_grad_norm=None, cupy=False, cutmix_alpha=1.0, data_path='/home/ridger/datasets/tiny-imagenet-200', device='cuda', disable_amp=False, disable_pinmemory=False, disable_uda=False, dist_url='env://', distributed=False, epochs=90, interpolation='bilinear', label_smoothing=0.1, local_rank=None, lr=0.01, lr_gamma=0.1, lr_scheduler='cosa', lr_step_size=30, lr_warmup_decay=0.01, lr_warmup_epochs=5, lr_warmup_method='linear', mixup_alpha=0.2, model='spiking_vgg11_bn', model_ema=False, model_ema_decay=0.99998, model_ema_steps=32, momentum=0.9, norm_weight_decay=None, opt='adamw', output_dir='./logs', pretrained=False, print_logdir=False, prototype=False, ra_reps=4, ra_sampler=False, random_erase=0.1, resume=None, seed=2020, start_epoch=0, sync_bn=False, test_only=False, train_crop_size=176, val_crop_size=224, val_resize_size=232, weight_decay=0.0, weights=None, workers=0, world_size=1)
Loading data
Loading training data
Took 2.132986068725586
Loading validation data
Creating data loaders
Creating model
SpikingVGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (1): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(64, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(4, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (3): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (6): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(128, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(8, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (8): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (11): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (13): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (15): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(16, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (17): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (20): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (21): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (22): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (24): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (26): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (29): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (31): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), step_mode=m)
    (33): CSA(
      (relu): ReLU(inplace=True)
      (ca): ChannelAttention(
        (avg_pool): AdaptiveAvgPool3d(output_size=1)
        (max_pool): AdaptiveMaxPool3d(output_size=1)
        (sharedMLP): Sequential(
          (0): Conv3d(512, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (1): ReLU()
          (2): Conv3d(32, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        )
        (sigmoid): Sigmoid()
      )
      (sa): SpatialAttention(
        (conv): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (sigmoid): Sigmoid()
      )
    )
    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, step_mode=m)
    (35): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False, step_mode=m)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7), step_mode=m)
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): LIFNode(
      v_threshold=1.0, v_reset=0.0, detach_reset=True, step_mode=m, backend=torch, tau=2.0
      (surrogate_function): ATan(alpha=2.0, spiking=True)
    )
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=200, bias=True)
  )
)